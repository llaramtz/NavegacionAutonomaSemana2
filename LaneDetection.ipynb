{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instalación de bibliotecas:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importar las bibliotecas necesarias:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leer el video usando OpenCV:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test_video.mp4')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definir los puntos de referencia para la región de interés (ROI) en la imagen del video. La ROI es la región en la que se buscarán los carriles:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Definir puntos de referencia para la región de interés\n",
    "height, width = cap.read()[1].shape[:2]\n",
    "\n",
    "#ROI_vertices = [(0, height), (width/2, height/2), (width, height)]\n",
    "ROI_vertices = [(200, height), (1100,height), (550, 250)]\n",
    "#ROI_vertices = [(0, 540), (200,300), (650, 300), (850, 540)]\n",
    "#ROI_vertices = [(200, height), (1100,height), (550, 250), (right_bottom_x, right_bottom_y)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def draw_lines(frame, lines):\n",
    "    \"\"\"\n",
    "    Esta función toma una imagen de entrada y una lista de líneas, y dibuja las líneas en la imagen.\n",
    "    \"\"\"\n",
    "    # Crear una imagen en negro para dibujar las líneas\n",
    "    line_image = np.zeros_like(frame)\n",
    "\n",
    "    # Dibujar cada línea en la imagen\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4)\n",
    "            cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 10)\n",
    "\n",
    "    # Combinar la imagen con las líneas con la imagen de entrada utilizando una operación bitwise OR\n",
    "    line_frame = cv2.addWeighted(frame, 0.8, line_image, 1, 0.0)\n",
    "\n",
    "    return line_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Crear una función para procesar cada cuadro del video. La función debe realizar las siguientes tareas:\n",
    "Definir la ROI utilizando los puntos de referencia definidos anteriormente.\n",
    "Convertir la imagen de entrada a escala de grises.\n",
    "Aplicar un filtro gaussiano para suavizar la imagen y reducir el ruido.\n",
    "Utilizar el operador Canny para detectar los bordes de los carriles.\n",
    "Utilizar la transformada de Hough para detectar las líneas en la imagen.\n",
    "Dibujar las líneas detectadas en la imagen de salida."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # Definir la ROI utilizando los puntos de referencia definidos anteriormente\n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    # Convertir los puntos de la ROI a un tipo de datos adecuado y verificar la forma del vector de entrada\n",
    "    vertices = np.array([ROI_vertices], dtype=np.int32)\n",
    "    #if vertices.shape != (1, 4, 2):\n",
    "     #   raise ValueError('ROI vertices must have shape (1, 4, 2)')\n",
    "\n",
    "    cv2.fillPoly(mask, vertices, (255, 255, 255))\n",
    "    masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "    # Convertir la imagen de entrada a escala de grises\n",
    "    gray = cv2.cvtColor(masked_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Aplicar un filtro gaussiano para reducir el ruido\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Detectar los bordes de la imagen utilizando el operador Canny\n",
    "    edges = cv2.Canny(blur, threshold1=50, threshold2=150)\n",
    "\n",
    "    # Definir los parámetros de la transformada de Hough\n",
    "    rho = 1  # Resolución en píxeles de la distancia rho\n",
    "    theta = np.pi / 180  # Resolución en radianes del ángulo theta\n",
    "    threshold = 15  # Umbral mínimo de votos para una línea\n",
    "    min_line_length = 40  # Longitud mínima en píxeles de una línea\n",
    "    max_line_gap = 20  # Máxima brecha en píxeles entre segmentos de línea para conectarlos en una sola línea\n",
    "\n",
    "    # Ejecutar la transformada de Hough\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "    # Dibujar las líneas detectadas en la imagen de salida\n",
    "    line_frame = draw_lines(frame, lines)\n",
    "\n",
    "    return line_frame\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Procesar cada cuadro del video y mostrar la imagen de salida:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Procesar cada cuadro del video y mostrar la imagen de salida\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        line_frame = process_frame(frame)\n",
    "        cv2.imshow('Video', line_frame)\n",
    "\n",
    "        # Salir al presionar la tecla 'q'\n",
    "        if cv2.waitKey(1) &  0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    else:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
